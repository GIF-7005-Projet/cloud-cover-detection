{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.imageio import get_X_paths, get_y_paths\n",
    "from datasets.dataset import CloudCoverDataset\n",
    "from datasets.transforms.minmax_normalize import MinMaxNormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class AveragedWelfordIncrementalVariance(object):\n",
    "    \"\"\"\n",
    "    Welford's algorithm computes the sample variance incrementally.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ddof: int = 0):\n",
    "        self.ddof = ddof\n",
    "        self.n = 0\n",
    "        self.mean = 0.0\n",
    "        self.M2 = 0.0\n",
    "\n",
    "    def accumulate(self, x_i: Union[np.ndarray, int, float]):\n",
    "        self.n += 1\n",
    "        self.delta = x_i - self.mean\n",
    "        self.mean += self.delta / self.n\n",
    "        self.M2 += self.delta * (x_i - self.mean)\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return np.mean(self.M2 / (self.n - self.ddof))\n",
    "\n",
    "    @property\n",
    "    def std(self):\n",
    "        return np.sqrt(self.variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each x can have up to 4 different feature types, one for R, G, B, Infrared.  \n",
    "Each feature is an image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[WindowsPath('../../data/final/public/train_features/adwp/B02.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwp/B03.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwp/B04.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwp/B08.tif')],\n",
       " [WindowsPath('../../data/final/public/train_features/adwu/B02.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwu/B03.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwu/B04.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwu/B08.tif')],\n",
       " [WindowsPath('../../data/final/public/train_features/adwz/B02.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwz/B03.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwz/B04.tif'),\n",
       "  WindowsPath('../../data/final/public/train_features/adwz/B08.tif')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_paths = get_X_paths()\n",
    "train_X_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../../data/final/public/train_labels/adwp.tif'),\n",
       " WindowsPath('../../data/final/public/train_labels/adwu.tif'),\n",
       " WindowsPath('../../data/final/public/train_labels/adwz.tif')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_paths = get_y_paths()\n",
    "train_y_paths[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CloudCoverDataset(\n",
    "    X_paths=train_X_paths, \n",
    "    y_paths=train_y_paths, \n",
    "    transforms=MinMaxNormalize(0, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6353140.5000)\n",
      "tensor(12082211.)\n",
      "tensor(17690556.)\n",
      "tensor(23615220.)\n",
      "tensor(29651418.)\n",
      "tensor(35528368.)\n",
      "tensor(41349632.)\n",
      "tensor(46677252.)\n",
      "tensor(50907164.)\n",
      "tensor(55189452.)\n",
      "tensor(60748044.)\n",
      "tensor(68020024.)\n",
      "tensor(74845544.)\n",
      "tensor(80989592.)\n",
      "tensor(86756648.)\n",
      "tensor(92750912.)\n",
      "tensor(97908736.)\n",
      "tensor(1.0397e+08)\n",
      "tensor(1.1017e+08)\n",
      "tensor(1.1667e+08)\n",
      "tensor(1.2351e+08)\n",
      "tensor(1.2996e+08)\n",
      "tensor(1.3720e+08)\n",
      "tensor(1.4536e+08)\n",
      "tensor(1.5348e+08)\n",
      "tensor(1.5827e+08)\n",
      "tensor(1.6219e+08)\n",
      "tensor(1.6683e+08)\n",
      "tensor(1.7173e+08)\n",
      "tensor(1.7658e+08)\n",
      "tensor(1.8485e+08)\n",
      "tensor(1.9354e+08)\n",
      "tensor(2.0166e+08)\n",
      "tensor(2.0615e+08)\n",
      "tensor(2.1078e+08)\n",
      "tensor(2.1653e+08)\n",
      "tensor(2.2240e+08)\n",
      "tensor(2.2849e+08)\n",
      "tensor(2.3531e+08)\n",
      "tensor(2.4236e+08)\n",
      "tensor(2.4964e+08)\n",
      "tensor(2.5593e+08)\n",
      "tensor(2.6123e+08)\n",
      "tensor(2.6532e+08)\n",
      "tensor(2.6875e+08)\n",
      "tensor(2.7300e+08)\n",
      "tensor(2.7795e+08)\n",
      "tensor(2.8409e+08)\n",
      "tensor(2.9098e+08)\n",
      "tensor(2.9667e+08)\n",
      "tensor(3.0145e+08)\n",
      "tensor(3.0678e+08)\n",
      "tensor(3.1419e+08)\n",
      "tensor(3.2151e+08)\n",
      "tensor(3.2842e+08)\n",
      "tensor(3.3529e+08)\n",
      "tensor(3.4184e+08)\n",
      "tensor(3.4846e+08)\n",
      "tensor(3.5515e+08)\n",
      "tensor(3.6203e+08)\n",
      "tensor(3.6860e+08)\n",
      "tensor(3.7534e+08)\n",
      "tensor(3.8097e+08)\n",
      "tensor(3.8646e+08)\n",
      "tensor(3.9311e+08)\n",
      "tensor(3.9864e+08)\n",
      "tensor(4.0421e+08)\n",
      "tensor(4.1054e+08)\n",
      "tensor(4.1746e+08)\n",
      "tensor(4.2258e+08)\n",
      "tensor(4.2654e+08)\n",
      "tensor(4.3082e+08)\n",
      "tensor(4.3605e+08)\n",
      "tensor(4.4148e+08)\n",
      "tensor(4.4626e+08)\n",
      "tensor(4.5065e+08)\n",
      "tensor(4.5474e+08)\n",
      "tensor(4.5858e+08)\n",
      "tensor(4.6400e+08)\n",
      "tensor(4.7062e+08)\n",
      "tensor(4.7755e+08)\n",
      "tensor(4.8431e+08)\n",
      "tensor(4.9061e+08)\n",
      "tensor(4.9685e+08)\n",
      "tensor(5.0382e+08)\n",
      "tensor(5.1070e+08)\n",
      "tensor(5.1428e+08)\n",
      "tensor(5.1815e+08)\n",
      "tensor(5.2253e+08)\n",
      "tensor(5.2723e+08)\n",
      "tensor(5.3340e+08)\n",
      "tensor(5.4057e+08)\n",
      "tensor(5.4782e+08)\n",
      "tensor(5.5425e+08)\n",
      "tensor(5.6043e+08)\n",
      "tensor(5.6629e+08)\n",
      "tensor(5.7402e+08)\n",
      "tensor(5.8275e+08)\n",
      "tensor(5.9161e+08)\n",
      "tensor(5.9879e+08)\n",
      "tensor(6.0349e+08)\n",
      "tensor(6.0813e+08)\n",
      "tensor(6.1389e+08)\n",
      "tensor(6.1937e+08)\n",
      "tensor(6.2498e+08)\n",
      "tensor(6.3039e+08)\n",
      "tensor(6.3524e+08)\n",
      "tensor(6.4107e+08)\n",
      "tensor(6.4474e+08)\n",
      "tensor(6.4850e+08)\n",
      "tensor(6.5435e+08)\n",
      "tensor(6.6010e+08)\n",
      "tensor(6.6727e+08)\n",
      "tensor(6.7449e+08)\n",
      "tensor(6.8075e+08)\n",
      "tensor(6.8533e+08)\n",
      "tensor(6.8994e+08)\n",
      "tensor(6.9558e+08)\n",
      "tensor(7.0290e+08)\n",
      "tensor(7.0673e+08)\n",
      "tensor(7.1109e+08)\n",
      "tensor(7.1689e+08)\n",
      "tensor(7.2350e+08)\n",
      "tensor(7.2998e+08)\n",
      "tensor(7.3709e+08)\n",
      "tensor(7.4491e+08)\n",
      "tensor(7.5249e+08)\n",
      "tensor(7.5882e+08)\n",
      "tensor(7.6534e+08)\n",
      "tensor(7.7166e+08)\n",
      "tensor(7.7983e+08)\n",
      "tensor(7.8779e+08)\n",
      "tensor(7.9307e+08)\n",
      "tensor(7.9833e+08)\n",
      "tensor(8.0262e+08)\n",
      "tensor(8.0868e+08)\n",
      "tensor(8.1554e+08)\n",
      "tensor(8.2128e+08)\n",
      "tensor(8.2664e+08)\n",
      "tensor(8.3190e+08)\n",
      "tensor(8.3884e+08)\n",
      "tensor(8.4580e+08)\n",
      "tensor(8.5299e+08)\n",
      "tensor(8.6041e+08)\n",
      "tensor(8.6515e+08)\n",
      "tensor(8.6888e+08)\n",
      "tensor(8.7341e+08)\n",
      "tensor(8.7902e+08)\n",
      "tensor(8.8455e+08)\n",
      "tensor(8.9018e+08)\n",
      "tensor(8.9803e+08)\n",
      "tensor(9.0584e+08)\n",
      "tensor(9.1359e+08)\n",
      "tensor(9.1995e+08)\n",
      "tensor(9.2674e+08)\n",
      "tensor(9.3256e+08)\n",
      "tensor(9.3826e+08)\n",
      "tensor(9.4422e+08)\n",
      "tensor(9.4951e+08)\n",
      "tensor(9.5430e+08)\n",
      "tensor(9.5903e+08)\n",
      "tensor(9.6538e+08)\n",
      "tensor(9.7223e+08)\n",
      "tensor(9.7899e+08)\n",
      "tensor(9.8439e+08)\n",
      "tensor(9.8894e+08)\n",
      "tensor(9.9333e+08)\n",
      "tensor(1.0013e+09)\n",
      "tensor(1.0097e+09)\n",
      "tensor(1.0181e+09)\n",
      "tensor(1.0247e+09)\n",
      "tensor(1.0304e+09)\n",
      "tensor(1.0367e+09)\n",
      "tensor(1.0422e+09)\n",
      "tensor(1.0475e+09)\n",
      "tensor(1.0532e+09)\n",
      "tensor(1.0601e+09)\n",
      "tensor(1.0673e+09)\n",
      "tensor(1.0741e+09)\n",
      "tensor(1.0805e+09)\n",
      "tensor(1.0861e+09)\n",
      "tensor(1.0915e+09)\n",
      "tensor(1.0961e+09)\n",
      "tensor(1.0988e+09)\n",
      "Mean: 0.35680079460144043, Standard Deviation: 0.20763736963272095\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "channel_index = 3\n",
    "\n",
    "# Initialize accumulators\n",
    "sums = 0.0\n",
    "sums_sq = 0.0\n",
    "n = 0\n",
    "\n",
    "for batch, _ in loader:\n",
    "    # Extract the fourth channel\n",
    "    channel_data = batch[:, channel_index]\n",
    "\n",
    "    # Update accumulators\n",
    "    sums += channel_data.sum()\n",
    "    sums_sq += (channel_data ** 2).sum()\n",
    "    n += channel_data.numel()\n",
    "    print(sums)\n",
    "\n",
    "# Compute mean and std\n",
    "mean = sums / n\n",
    "variance = (sums_sq / n) - (mean ** 2)\n",
    "std = torch.sqrt(variance)\n",
    "\n",
    "print(f\"Mean: {mean.item()}, Standard Deviation: {std.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
