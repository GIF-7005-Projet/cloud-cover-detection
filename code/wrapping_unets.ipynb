{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Subset, random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.datasets.imageio import get_X_paths, get_y_paths\n",
    "from src.datasets.dataset import CloudCoverDataset\n",
    "from src.datasets.transforms.minmax_normalize import MinMaxNormalize\n",
    "from src.datasets.exploration.visualization import show_rgb_infrared_ground_truth, show_channels, show_stats, show_class_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each x can have up to 4 different feature types, one for R, G, B, Infrared.  \n",
    "Each feature is an image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[WindowsPath('../data/final/public/train_features/adwp/B02.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwp/B03.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwp/B04.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwp/B08.tif')],\n",
       " [WindowsPath('../data/final/public/train_features/adwu/B02.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwu/B03.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwu/B04.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwu/B08.tif')],\n",
       " [WindowsPath('../data/final/public/train_features/adwz/B02.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwz/B03.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwz/B04.tif'),\n",
       "  WindowsPath('../data/final/public/train_features/adwz/B08.tif')]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_paths = get_X_paths()\n",
    "train_X_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../data/final/public/train_labels/adwp.tif'),\n",
       " WindowsPath('../data/final/public/train_labels/adwu.tif'),\n",
       " WindowsPath('../data/final/public/train_labels/adwz.tif')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_paths = get_y_paths()\n",
    "train_y_paths[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CloudCoverDataset(X_paths=train_X_paths, y_paths=train_y_paths)\n",
    "train_ds = Subset(train_ds, list(range(500)))\n",
    "\n",
    "total_size = len(train_ds)\n",
    "val_size = int(total_size * 0.2)  # let's say 20% for validation\n",
    "train_size = total_size - val_size\n",
    "train_subset, val_subset = random_split(train_ds, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_for_analysis = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_subset, batch_size=sample_size_for_analysis, shuffle=True, num_workers=11, persistent_workers=True)\n",
    "val_dl = DataLoader(val_subset, batch_size=sample_size_for_analysis, shuffle=False, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "# MODÈLE UNET MAISON. LE UNET SE DIVISE EN TROIS PARTIES (DÉBUT, DOWN, UP).\n",
    "\n",
    "# Premières couches du modèle\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "# DESCENTE\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "# MONTÉE\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# LA SORTIE\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# TOUTES LES COUCHES COMBINÉES DANS L'ORDRE\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024 // 2)\n",
    "        self.up1 = Up(1024, 512 // 2, bilinear)\n",
    "        self.up2 = Up(512, 256 // 2, bilinear)\n",
    "        self.up3 = Up(256, 128 // 2, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningUNet(pl.LightningModule):\n",
    "    def __init__(self, n_channels, n_classes, train_loader, val_loader=None, test_loader=None, bilinear=True, learning_rate=1e-3):\n",
    "        super(LightningUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.bilinear = bilinear\n",
    "        self.learning_rate = learning_rate\n",
    "        self.jaccard_index = torchmetrics.JaccardIndex(num_classes=n_classes, task='binary')\n",
    "\n",
    "        # Architecture Unet\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024 // 2)\n",
    "        self.up1 = Up(1024, 512 // 2, bilinear)\n",
    "        self.up2 = Up(512, 256 // 2, bilinear)\n",
    "        self.up3 = Up(256, 128 // 2, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        target_for_loss = target.long()\n",
    "        output = self(inputs)\n",
    "        \n",
    "        # Jaccard Index Computation\n",
    "        predicted_labels = torch.argmax(output, dim=1)\n",
    "        self.jaccard_index(predicted_labels, target)\n",
    "        self.log('train_jaccard', self.jaccard_index, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(output, target_for_loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        target_for_loss = target.long()\n",
    "        output = self(inputs)\n",
    "\n",
    "        loss = F.cross_entropy(output, target_for_loss)\n",
    "        \n",
    "        # Jaccard Index Computation\n",
    "        predicted_labels = torch.argmax(output, dim=1)\n",
    "        self.jaccard_index(predicted_labels, target)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_jaccard', self.jaccard_index, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        target_for_loss = target.long()\n",
    "        output = self(inputs)\n",
    "        \n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        # Jaccard Index Computation\n",
    "        predicted_labels = torch.argmax(output, dim=1)\n",
    "        self.jaccard_index(predicted_labels, target_for_loss)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('test_jaccard', self.jaccard_index, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader if self.val_loader else None\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_loader if self.test_loader else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name          | Type               | Params\n",
      "------------------------------------------------------\n",
      "0  | jaccard_index | BinaryJaccardIndex | 0     \n",
      "1  | inc           | DoubleConv         | 39.6 K\n",
      "2  | down1         | Down               | 221 K \n",
      "3  | down2         | Down               | 886 K \n",
      "4  | down3         | Down               | 3.5 M \n",
      "5  | down4         | Down               | 4.7 M \n",
      "6  | up1           | Up                 | 5.9 M \n",
      "7  | up2           | Up                 | 1.5 M \n",
      "8  | up3           | Up                 | 369 K \n",
      "9  | up4           | Up                 | 110 K \n",
      "10 | outc          | OutConv            | 130   \n",
      "------------------------------------------------------\n",
      "17.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 M    Total params\n",
      "69.072    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e9722388bd465fabaaa116ce834daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric BinaryJaccardIndex was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "model = LightningUNet(4, 2, train_dl, val_dl, bilinear=True, learning_rate=1e-3)\n",
    "trainer = Trainer(max_epochs=10)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/model.ckpt\"\n",
    "trainer.save_checkpoint(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
