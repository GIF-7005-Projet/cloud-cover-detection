{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.data_module import CloudCoverDataModule\n",
    "from pathlib import Path\n",
    "from src.models.unet import LightningUNet\n",
    "from src.training.trainer import train\n",
    "from src.testing.tester import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = CloudCoverDataModule(\n",
    "    train_X_folder_path=Path(\"../data/final/public/train_features/\"),\n",
    "    train_y_folder_path=Path(\"../data/final/public/train_labels/\"),\n",
    "    test_X_folder_path=Path(\"../data/final/private/test_features/\"),\n",
    "    test_y_folder_path=Path(\"../data/final/private/test_labels/\"),\n",
    "    train_batch_size=4,\n",
    "    val_batch_size=8,\n",
    "    test_batch_size=8,\n",
    "    val_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.setup(stage=\"fit\")\n",
    "data_module.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import pytorch_lightning as pl\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "\n",
    "# MODELE DEEPLAB\n",
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.dilations = [1, 6, 12, 18]\n",
    "        self.aspp_blocks = nn.ModuleList()\n",
    "\n",
    "        for dilation in self.dilations:\n",
    "            self.aspp_blocks.append(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation)\n",
    "            )\n",
    "        self.output_conv = nn.Conv2d(len(self.dilations) * out_channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        aspp_outputs = [block(x) for block in self.aspp_blocks]\n",
    "        x = torch.cat(aspp_outputs, dim=1)\n",
    "        x = self.output_conv(x)\n",
    "        return x\n",
    "\n",
    "class DeepLabV3(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super(DeepLabV3, self).__init__()\n",
    "        # Load a pretrained ResNet model\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "\n",
    "        original_first_layer = self.backbone.conv1\n",
    "        # Create a new Conv2d layer with 4 input channels instead of 3\n",
    "        self.backbone.conv1 = nn.Conv2d(in_channels,  # Change from 3 to 4\n",
    "                                        original_first_layer.out_channels, \n",
    "                                        kernel_size=original_first_layer.kernel_size, \n",
    "                                        stride=original_first_layer.stride, \n",
    "                                        padding=original_first_layer.padding, \n",
    "                                        bias=False)\n",
    "        \n",
    "        # Copy the weights from the original first layer to the new layer\n",
    "        with torch.no_grad():\n",
    "            self.backbone.conv1.weight[:, :3] = original_first_layer.weight\n",
    "            # Initialize the extra channel weights with zeros or another preferred method\n",
    "            self.backbone.conv1.weight[:, 3] = torch.zeros_like(self.backbone.conv1.weight[:, 0])\n",
    "        \n",
    "        # Replace the fully connected layer of ResNet with ASPP\n",
    "        in_channels = 2048  # Depends on the ResNet model\n",
    "        self.aspp = ASPP(in_channels, 256)\n",
    "\n",
    "        # Final convolutional layers\n",
    "        self.conv1 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, num_classes, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from the backbone\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        # Pass features through ASPP\n",
    "        x = self.aspp(x)\n",
    "\n",
    "        # Additional convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        # Upsample the output to the size of the input\n",
    "        x = F.interpolate(x, scale_factor=16, mode='bilinear', align_corners=False)\n",
    "        return x\n",
    "\n",
    "class LightningDeeplab(pl.LightningModule):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.model = DeepLabV3(n_classes, n_channels)\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.train_jaccard = torchmetrics.JaccardIndex(num_classes=n_classes, task='binary')\n",
    "        self.train_accuracy = torchmetrics.Accuracy(num_classes=n_classes, task='binary', average='macro')\n",
    "        \n",
    "        self.val_jaccard = torchmetrics.JaccardIndex(num_classes=n_classes, task='binary')\n",
    "        self.val_accuracy = torchmetrics.Accuracy(num_classes=n_classes, task='binary', average='macro')\n",
    "        \n",
    "        self.test_jaccard = torchmetrics.JaccardIndex(num_classes=n_classes, task='binary')\n",
    "        self.test_accuracy = torchmetrics.Accuracy(num_classes=n_classes, task='binary', average='macro')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        y_hat = self(inputs)\n",
    "        y_hat = F.interpolate(y_hat, size=target.size()[1:], mode='bilinear', align_corners=False)\n",
    "        predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        loss = self.compute_loss(y_hat, target)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "\n",
    "        self.train_jaccard(predicted_labels, target)\n",
    "        self.log('train_jaccard', self.train_jaccard, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.train_accuracy(predicted_labels, target)\n",
    "        self.log('train_accuracy', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def compute_loss(self, y_hat, y):\n",
    "        return F.cross_entropy(y_hat, y)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        inputs, target = batch\n",
    "        y_hat = self(inputs)\n",
    "        y_hat = F.interpolate(y_hat, size=target.size()[1:], mode='bilinear', align_corners=False)\n",
    "        predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        loss = self.compute_loss(y_hat, target)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.val_jaccard(predicted_labels, target)\n",
    "        self.log('val_jaccard', self.val_jaccard, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.val_accuracy(predicted_labels, target)\n",
    "        self.log('val_accuracy', self.val_accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, target = batch\n",
    "        y_hat = self(inputs)\n",
    "        y_hat = F.interpolate(y_hat, size=target.size()[1:], mode='bilinear', align_corners=False)\n",
    "        predicted_labels = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        loss = self.compute_loss(y_hat, target)\n",
    "        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.test_jaccard(predicted_labels, target)\n",
    "        self.log('test_jaccard', self.test_jaccard, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.test_accuracy(predicted_labels, target)\n",
    "        self.log('test_accuracy', self.test_accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | model          | DeepLabV3          | 45.3 M\n",
      "1 | train_jaccard  | BinaryJaccardIndex | 0     \n",
      "2 | train_accuracy | BinaryAccuracy     | 0     \n",
      "3 | val_jaccard    | BinaryJaccardIndex | 0     \n",
      "4 | val_accuracy   | BinaryAccuracy     | 0     \n",
      "5 | test_jaccard   | BinaryJaccardIndex | 0     \n",
      "6 | test_accuracy  | BinaryAccuracy     | 0     \n",
      "------------------------------------------------------\n",
      "45.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "45.3 M    Total params\n",
      "181.154   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcd56dfb5a14016863f02e5b29e8034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "deeplab = train(\n",
    "    model=LightningDeeplab(n_channels=4, n_classes=2, bilinear=True, learning_rate=0.001),\n",
    "    run_name=\"deeplab\",\n",
    "    model_version=0,\n",
    "    data_module=data_module,\n",
    "    max_epochs=2,\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test  \n",
    "Replace the checkpoint path with the best checkpoint from the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplab = LightningDeeplab.load_from_checkpoint(checkpoint_path='./logs/deeplab/version_0/checkpoints/deeplab-epoch=01-val_loss=0.67.ckpt', n_channels=4, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\ultav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772982901b734536a6188b0f6e4dc553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                       | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_accuracy_epoch      0.6116666197776794\n",
      "   test_jaccard_epoch       0.6116637587547302\n",
      "     test_loss_epoch         0.676939845085144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "test(\n",
    "    model=deeplab,\n",
    "    run_name=\"deeplab\",\n",
    "    model_version=0,\n",
    "    data_module=data_module\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
